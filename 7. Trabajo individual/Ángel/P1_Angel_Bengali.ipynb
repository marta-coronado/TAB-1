{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i class=\"fa fa-laptop\"></i> Hands-on training 1: Data management and processing\n",
    "\n",
    "<div style=\"background-color: #86CBBB; 1px; height:3px \" ></div>\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "We are about to start a journey into real Bioinformatics. This series of **four hands-on training activities** will show you how to analyze real **next-generation sequencing** (NGS) data, starting from the primary raw data from an Illumina sequencer, learning in the process the **data management and processing**, **visualization**, and posterior **functional analyses**. The practicals are divided into two big parts: **Part I: Basics on Bioinformatics workflows: Transforming data into insight** and **Part II: Solving real cases in genomics**.\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/logoTAB2019_10_27D8_47_29.png\" width=55%>\n",
    "</center>\n",
    "\n",
    "These practicals pretend also to gain other skills, very valuable in research but rarely experienced during the Degree, such as **collaborating** and **doing reproducible research**.\n",
    "\n",
    "### 1.1 Part I: Basics on Bioinformatics workflows\n",
    "\n",
    "The workflow of the first part, **Basics on Bioinformatics workflows: Transforming data into insight**, is summarized in the following figure: \n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/workflow2019_10_27D9_48_7.png\" width=40%>\n",
    "</center>\n",
    "\n",
    "In this first practical (P1), **Data management and processing**, you will face different biological data formats (such as genomic sequences, annotation files or alignments). Getting familiar with the properties and structure of each type of data and the tools to analyze is key in bioinformatics. In the second practical (P2), **Data exploration and visualization**, we will transform the produced data of P1 into knowledge graphs. \n",
    "\n",
    "#### P1 Learning outcomes\n",
    "\n",
    "* Check the data quality of an NGS experiment\n",
    "* Call genome variations\n",
    "* Find variants of interest\n",
    "* Get familiar with common NGS data types (e.g.: VCF, BAM, GFF, FASTQC, ...)\n",
    "* Use the Linux command-line to perform simple tasks on the data\n",
    "\n",
    "#### P2 Learning outcomes\n",
    "\n",
    "* Learn the grammar of graphics of `ggplot2`\n",
    "* Create the most common bioinformatics graphs (scatterplots, lineplots, barplots, ...)\n",
    "* Understand the important elements of a ready-to-publish figure\n",
    "\n",
    "### 1.2 Practicals organization\n",
    "\n",
    "#### 1.2.1 Jupyter Notebook\n",
    "\n",
    "In these practicals, we are going to use **Jupyter Notebook** dashboard. A Jupyter Notebook is an interactive work environment that allows you to develop code in Python (and not only Python) dynamically, integrating blocks of code, text, graphics and images in the same document. It emerged in 2014 to offer the scientific community a very powerful set of tools to work with data, visualize it and be able to share the results with the community.\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/jupyterpreview2019_10_27D10_6_30.png\n",
    "\" width=45%>\n",
    "</center>\n",
    "\n",
    "This **new work philosophy** contrasts a lot with the idea that we usually have what programming and writing code is. This way of programming, called **literary programming**, emphasizes the purpose of writing comfortable text to read and understand, separated by blocks of code, combining text, equations and figures, and allowing sharing your research and results very easily.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#ffddad;\">  \n",
    "    <i class=\"fa fa-book\"></i> Read the following article published in Nature, where the benefits of using Jupyter Notebook for scientific research are emphasized: <b>Shen, H. (2014) Interactive notebooks: Sharing the code. <i>Nature</i> 2014 515:151-152</b>.\n",
    "</div>\n",
    "\n",
    "#### 1.2.2 `conda`\n",
    "\n",
    "Also, we are going to work in a **`conda` environment**. `conda` is an open-source package management system and environment management system. Conda installs, runs and updates packages and their dependencies, allowing you to work in independent environments according to your software needs.\n",
    "\n",
    "#### 1.2.3 Writing a report\n",
    "\n",
    "Finally, to **write our scientific reports**, we recommend using an online $\\LaTeX$ editor that's easy to use: [**Overleaf**](https://www.overleaf.com). We have created a ready-to-use template available [here](https://www.overleaf.com/read/vchzpswtycyg) so you can write your results.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#ffddad;\">  \n",
    "    <i class=\"fa fa-info-circle\"></i> In the UAB computers we already have <code style=\"background-color:#ffddad\">conda</code> installed with the environments <code style=\"background-color:#ffddad\">TAB</code> and <code style=\"background-color:#ffddad\">bioinformatics</code> that have installed all the libraries used in these practicals.\n",
    "</div>\n",
    "\n",
    "Go to section **2. Tools installation** for instructions on how to install Jupyter Notebook, `conda` and the libraries used in this practical.\n",
    " \n",
    "### 1.3. Jupyter Notebook menu\n",
    "\n",
    "All navigation and actions in the Jupyter Notebook are available using the mouse through the toolbar:\n",
    "\n",
    "&emsp;<i class=\"fa fa-save\"></i>save changes and creates a checkpoint  \n",
    "&emsp;<i class=\"fa fa-plus\"></i> insert a cell below a selected cell  \n",
    "&emsp;<i class=\"fa fa-scissors\"></i> cut selected cell(s)  \n",
    "&emsp;<i class=\"fa fa-copy\"></i> copy selected cell(s)  \n",
    "&emsp;<i class=\"fa fa-paste\"></i> paste cell(s) below  \n",
    "&emsp;<i class=\"fa fa-arrow-up\"></i> move selected cell(s) up  \n",
    "&emsp;<i class=\"fa fa-arrow-down\"></i> move selected cell(s) down  \n",
    "&emsp;<i class=\"fa fa-step-forward\"></i> run a cell  \n",
    "&emsp;<i class=\"fa fa-stop\"></i> interrupt the kernel  \n",
    "&emsp;<i class=\"fa fa-repeat\"></i> restart the kernel  \n",
    "&emsp;<i class=\"fa fa-forward\"></i> restart the kernel, then re-run the whole notebook\n",
    " \n",
    "##### Shortcuts\n",
    "\n",
    "We recommend learning the command-mode shortcuts:\n",
    "\n",
    "&emsp;**Basic navigation**: enter, shift-enter, up/k, down/j  \n",
    "&emsp;**Saving the notebook**: s  \n",
    "&emsp;**Change cell types**: c, m  \n",
    "&emsp;**Cell creation**: a, b  \n",
    "&emsp;**Cell editing**: x, c, v, d, z  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #86CBBB; 1px; height:3px \" ></div>\n",
    "\n",
    "# 2. Tools installation \n",
    "\n",
    "We strongly recommend using a **Linux** operating system and get used to work with the **terminal**. If you're using **Windows 10**, a good alternative is to install **Ubuntu 18.04** on it. The application is available in the [Microsoft Store](https://www.microsoft.com/en-us/p/ubuntu-1804-lts/9n9tngvndl3q?activetab=pivot:overviewtab).     Simply click on the *Install* button, and it will be downloaded and installed automatically. When launched for the first time, Ubuntu will inform you that it's *Installing* and you'll need to wait a few moments. When complete, you'll be asked for a username and password specific to your Ubuntu installation. With this step complete, you'll find yourself at the Ubuntu bash command line.\n",
    "\n",
    "## 2.1 Installing `conda`\n",
    "\n",
    "1. Download the installer:\n",
    "\n",
    "    1. [Miniconda installer for Linux](https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh) (Linux 64 bits)\n",
    "    2. [Anaconda installer for Linux](https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh) (Linux 64 bits)\n",
    "\n",
    "Both Anaconda and Miniconda uses `conda` as the package manager. The difference is that Miniconda only has the package management system, while Anaconda also comes with a bundle of pre-installed packages (e.g. `jupyterlab`, which contains Jupyter Notebook).\n",
    "\n",
    "2. In your terminal window, run:\n",
    "\n",
    "    1. Miniconda:\n",
    "<code style=\"background-color:#222D32; color:#FFF\">bash Miniconda3-latest-Linux-x86_64.sh\n",
    "</code>\n",
    "    2. Anaconda: <code style=\"background-color:#222D32; color:#FFF\">bash Anaconda3-2019.10-Linux-x86_64.sh\n",
    "</code>\n",
    "\n",
    "3. Follow the prompts on the installer screens.\n",
    "4. If you are unsure about any setting, accept the defaults. You can change them later.\n",
    "5. To make the changes take effect, close and then re-open your terminal window.\n",
    "\n",
    "You'll know that `conda` is installed because your command-line will be preceded with `(base)` to denote you are in your `base` conda environment.\n",
    "\n",
    "## 2.2 Creating a new environment\n",
    "\n",
    "To create a new environment, simply run:\n",
    "<code style=\"background-color:#222D32; color:#FFF\">conda create --name myEnv\n",
    "</code>\n",
    "\n",
    "And a new environment with the name `myEnv` will be created. To switch from the default environment (`base`) to the new one, run in the terminal: \n",
    "\n",
    "<code style=\"background-color:#222D32;color:#FFF\">conda deactivate</code><br>\n",
    "<code style=\"background-color:#222D32;color:#FFF\">conda activate myEnv</code>\n",
    "\n",
    "Packages installed in `myEnv` won't interfiere with the ones installed in your `base` environment. \n",
    "\n",
    "## 2.3 Installing packages\n",
    "\n",
    "You can easily install `conda` packages from the repository [**Anaconda Cloud**](https://anaconda.org/).\n",
    "\n",
    "In this practical, the following packages were installed:\n",
    "\n",
    "* [`samtools`](https://anaconda.org/bioconda/samtools)\n",
    "* [`quast`](https://anaconda.org/bioconda/quast)\n",
    "* [`fastqc`](https://anaconda.org/bioconda/fastqc)\n",
    "* [`vcftools`](https://anaconda.org/bioconda/vcftools)\n",
    "* [`bcftools`](https://anaconda.org/bioconda/bcftools)\n",
    "\n",
    "To install any of the above packages with `conda` simply run one the first command in your terminal. For example:\n",
    "\n",
    "<code style=\"background-color:#222D32;color:#FFF\"> conda install -c bioconda bcftools </code>\n",
    "\n",
    "will install `bcftools` in your current `conda` environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #86CBBB; 1px; height:3px \" ></div>\n",
    "\n",
    "# 3. Quick introduction to Linux\n",
    "\n",
    "In Linux, **folder navigation** and **program executions** are performed in the terminal by typing commands. You can open a terminal using the `Ctrl` + `Alt` + `T` shortcut, or looking for the `Konsole` or `Terminal` application from the installed programs list in your computer.\n",
    "\n",
    "You can also use Linux commands inside the Jupyter Notebook by specifying `%%bash` at the top of the cell. If nothing is specified, then the commands are expected to be in the Python programming language.<br>\n",
    "\n",
    "This table exemplifies the usage the most common commands used in Linux:\n",
    "\n",
    "| command          | function                           |\n",
    "|--------------|-------------------------------------------------------|\n",
    "| `pwd`          | print the current working directory                               |\n",
    "| `cd <dir>`     | change to  directory \"dir\"                         |\n",
    "| `ls`           | list files and directories of current directoy        |\n",
    "| `grep` |  searches the given file for lines containing a match to the given strings or words |\n",
    "| `cut` |  cutting out the sections from each line of files |\n",
    "| `cat`          | print file content (use `less` instead if file is too large) |\n",
    "| `\\| wc -l` | prints the line count  |  \n",
    "| `mkdir <name>` | create a new folder with name \"name\" |\n",
    "| `wget <url>` | download the contents from a link in the current directory |\n",
    "| `cat filetmp \\| cut -f1 > file` | redirect the output of a command to a file |\n",
    "| `gunzip file.gz` | uncompress a gz file |\n",
    "\n",
    "\n",
    "<i class=\"fa fa-search\"></i> Example of the `ls` command runing from the terminal:<br><br>\n",
    "\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">&emsp;(TAB)<b><span style=\"color:#86CBBB\">1244149@MRB014</span>:<span style=\"color:#ffddad\">~/Documents/Project</span></b>$ ls</code>\n",
    "</div><br>\n",
    "\n",
    "<i class=\"fa fa-search\"></i> Example of the `ls` command runing from the Jupyer Notebook:<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"background-color:#ffddad;\">  \n",
    "    <i class=\"fa fa-info-circle\"></i> The way to get more comfortable with the command-line is: <b>PRACTICE</b>. And keep the <a href=\"https://files.fosswire.com/2007/08/fwunixref.pdf\" target=\"_blank\">cheat sheet</a> close to you.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #86CBBB; 1px; height:3px \" ></div>\n",
    "\n",
    "# 4. Download and explore the data\n",
    "\n",
    "<center>\n",
    "        <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/prepSeqAna2019_10_27D17_14_29.png\" width=30%>\n",
    "</center>\n",
    "\n",
    "We will use real NGS data of **17 individuals** of **16 different populations** from **four distinct geographic origins**: Africa, Europe, East Asia and South Asia. This data comes from the 1000 Genomes Project (1000GP), that provides a comprehensive description of common human genetic variation by applying whole-genome sequencing to a diverse set of individuals from multiple populations ([The 1000 Genomes Project Consortium 2015](https://www.nature.com/articles/nature15393)). In particular, these individuals have been sequenced with **high coverage** using the **Illumina HiSeq 2500 sequencer**. Should you want to learn more about the sequencing, you can read Section 3.3. of the [Supplementary material](https://media.nature.com/original/nature-assets/nature/journal/v526/n7571/extref/nature15393-s1.pdf) of the 1000GP publication.\n",
    "\n",
    "Specifically,  the  following  17 individuals have been selected: \n",
    "\n",
    "| ID      | Sex    | Population | Origin               | Metapopulation |\n",
    "|---------|--------|------------|----------------------|----------------|\n",
    "| HG02922 | female | ESN        | Esan                 | AFR            |\n",
    "| NA19017 | female | LWK        | Luhya                | AFR            |\n",
    "| HG02568 | female | GWD        | Gambian Mandinka     | AFR            |\n",
    "| NA19240 | female | YRI        | Yoruba               | AFR            |\n",
    "| HG01879 | male | ACB        | African Caribbean               | AFR            |\n",
    "| NA18525 | female | CHB        | Han Chinese          | EAS            |\n",
    "| HG00419 | female | CHS        | Southern Han Chinese | EAS            |\n",
    "| NA18939 | female | JPT        | Japanese             | EAS            |\n",
    "| HG01595 | female | KHV        | Kinh Vietnamese      | EAS            |\n",
    "| NA20502 | female | TSI        | Toscani              | EUR            |\n",
    "| HG00268 | female | FIN        | Finnish              | EUR            |\n",
    "| NA12878 | female | CEU        | CEPH                 | EUR            |\n",
    "| HG01500 | male | IBS        | Iberian                 | EUR            |\n",
    "| HG01583 | male   | PJL        | Punjabi              | SAS            |\n",
    "| HG03742 | male   | ITU        | Telugu               | SAS            |\n",
    "| HG03006 | male   | BEB        | Bengali      | SAS            |\n",
    "| NA20845 | male   | GIH        | Gujarati             | SAS            |\n",
    "\n",
    "The raw data is available to download via [FTP](ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data). This FTP directory contain a folder for each sequenced individual (that correspond to its ID). Inside each individual folder, there are three/four folders, depending on the depth of the sequencing. The structure is as follows:\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/folders2019_10_27D17_50_33.png\" width=30%>\n",
    "</center>\n",
    "\n",
    "We are interested on the contens of the `high_coverage_alignment` folder. It only contains a **BAM file**. BAM files (from Binary Alignment Map) are used to store aligned (or *mapped*) high-throughput sequencing data. The file simply contain a header section and an alignment section of each sequenced read.\n",
    "\n",
    "We're not interested in analyzing the whole human genome --also, we do not have enough space and computer capacity for that--. We will focus on a **specific region of the chromosome 2 (134800000-137500000)**, so it's not necessary that we download the whole BAM file of each individual, but only the aligned reads of that particular region of the chromosome.\n",
    "\n",
    "For achieving that, we will use the `samtools` software ([Li et al., 2009](https://academic.oup.com/bioinformatics/article/25/16/2078/204688)), a suit of utilities for interacting with and post-processing short DNA sequence read alignments in the BAM format. But first, we need to set up our working space!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <i class=\"fa fa-cogs\"></i> Step 1: Create a working directory\n",
    "\n",
    "When starting any bioinformatic pipeline, usualy the first step to do is to create the folder where we'll place all our data and scripts. This is called the _working directory_.\n",
    "\n",
    "Create a folder in your preferred directory (e.g.: in the Desktop, your Home folder, or your Documents folder) named `ProjectP1`. Inside this project, you'll create new folders, containing the raw data, the scripts, etc.\n",
    "\n",
    "The first folder that `ProjectP1` will contain is the `data` folder, and inside, a `bams` folder. The structure should look like the following:\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/structure12019_10_27D18_10_3.png\" width=20%>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Write the commands to create the folders. Move to the bams folder\n",
    "\n",
    "ls\n",
    "cd Escritorio\n",
    "mkdir ProjectP1\n",
    "cd ProjectP1\n",
    "mkdir data\n",
    "cd data\n",
    "mkdir bams\n",
    "cd bams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <i class=\"fa fa-cogs\"></i> Step 2: Download the data inside the `bams` folder\n",
    "\n",
    "We're going to download the BAM files from the FTP. First, **choose an individual** from **one metapopulation**, distinct from the others individuals chosen by other groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `samtools` package is able to get a particular region of a BAM file. For that, it uses the `view -h` argument, followed by the location of the BAM file (in this case, a FTP link). If we want to download a specific region of the BAM file, we will write the chromosome and the start and end positions with the notation `chr:start-end`. And finally, in Linux, we use the symbol `>` to redirect the output of a command to a file. For example, if we want to download the region 100-200 of chromosome 12 of the individual HG01583, we will write:<br>\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">   \n",
    "    <code style=\"background-color:#222D32; color:#FFF\">samtools view -h ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG01583/high_coverage_alignment/HG01583.wgs.ILLUMINA.bwa.PJL.high_cov_pcr_free.20140203.bam 12:100-200 > HG01583.PJL.chr12:100-200.bam</code>\n",
    "</div>\n",
    "\n",
    "<i class=\"fa fa-info-circle\"></i> Note that the output file can have any name you want, but here it is used the notation `ID.Population.ChrX:Start-End.bam` because of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download the bam files of a region of chr2 of the chosen individual\n",
    "\n",
    "samtools view -h http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG03006/high_coverage_alignment/HG03006.wgs.ILLUMINA.bwa.BEB.high_cov_pcr_free.20140203.bam 2:134800000-137500000 > HG03006.BEB.chr2:134800000-137500000.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <i class=\"fa fa-key\"></i> How can you identify which file do you need to download from the FTP? First find the individual from the [FTP list](ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data) using its `ID`, enter the `high_coverage_alignment` folder and the file you are looking for has the bam file extension. You can also recognize it because generally will be the biggest file of the folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #86CBBB; 1px; height:3px \" ></div>\n",
    "\n",
    "# 5. Genome assembly\n",
    " \n",
    "## 5.1 Download a reference genome\n",
    "\n",
    "Once we have the sequence data of the individual, we need another important information: **a reference genome**. One of the main applications of the NGS technologies is finding variants/mutations of interest. Sequencing reads from different individuals are generated and single nucleotide polymorphisms (SNPs) and indels are looked for by comparing them with a reference genome:\n",
    "\n",
    "<center>\n",
    "        <img src=\"https://bioinformatica.uab.cat/base/continguts/documents/documents.asp?link=documents\\sgbcursos\\documents\\variant2019_10_27D18_39_37.png\" width=50%>\n",
    "</center>\n",
    "\n",
    "The reference genome can also be downloaded from the [FTP site](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.gz) of the 1000 GP. We are going to download reference genome version hg19/GRCh37."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <i class=\"fa fa-cogs\"></i> Step 1: Create an `assembly` folder\n",
    "\n",
    "Create a folder named `assembly` inside your `data` folder. Once created, navigate to that folder.\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/structure22019_10_27D18_56_11.png\" width=25%>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Write the commands to create the folder. Move to the assembly folder\n",
    "\n",
    "cd ..\n",
    "mkdir assembly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <i class=\"fa fa-cogs\"></i> Step 2: Download the data in the `assembly` folder\n",
    "\n",
    "This time we won't download a particular region of the genome, instead, we'll download the whole human genome assembly from the [FTP site](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/) (version hg19/GRCh37). In particular, we need two files: a fasta file ([human_g1k_v37.fasta.gz](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.gz)) and the indexed file ([human_g1k_v37.fasta.fai](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.fai)). For downloading the data, you can use the `wget` command followed by the url. Once downloaded, you can uncompress the gz file using the `gunzip` command.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">   \n",
    "    <code style=\"background-color:#222D32; color:#FFF\">wget url.fasta.gz</code><br> \n",
    "    <code style=\"background-color:#222D32; color:#FFF\">gunzip fasta.gz</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download the fasta \n",
    "\n",
    "cd assembly\n",
    "wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.gz\n",
    "wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.fai\n",
    "gunzip human_g1k_v37.fasta.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Assembly statistics\n",
    "\n",
    "How good is the 1000GP genome assembly? Quast (QUality ASsesment Tool) [Gurevich et al., 2013](https://academic.oup.com/bioinformatics/article/29/8/1072/228832), evaluates genome assemblies by computing various metrics, including the **N50** or the **L50 index**, measures used to describe the quality of assembled genomes.\n",
    "\n",
    "For running `quast`, the command is as follows:\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">   \n",
    "    <code style=\"background-color:#222D32; color:#FFF\">quast -o outputFolderName reference.fasta\n",
    "</code>\n",
    "</div>\n",
    "\n",
    "And it will crate several files and folders in the `outputFolderName` you specify in the command (e.g. create a folder called `quast` inside the `assembly` folder). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Run quast in the genome assembly\n",
    "\n",
    "cd assembly\n",
    "mkdir quast\n",
    "quast -o quast human_g1k_v37.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <i class=\"fa fa-pencil\"></i>  Explore the `report.pdf` file. What are  the genome assembly statistics of the human genome? Is it better or worse compared to the [most recent human genome assembly](https://www.ncbi.nlm.nih.gov/assembly/GCF_000001405.39)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-comment\"></i> If we compare the values of N50, our assembly has a higher value, which indicates that half of the reads is equal to or greater than 57.879.411."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #86CBBB; 1px; height:3px \" ></div>\n",
    "\n",
    "# 6. Quality control\n",
    "\n",
    "Thanks to the technological advances we are achieving highly accurate genome sequences. However, sequencing methods are imperfect ([Robasky, et al. 2014](https://www.nature.com/articles/nrg3655)). There are different source of errors: from the sample preparation (degradation, contamination, low DNA input...), library preparation (PCR amplification errors, user errors...) and sequencing errors. Each sequencing method is more prone to a particular source of error and it's very important to account for them when analyzing NGS data since some errors can mimic genetic variation.\n",
    "\n",
    "####  <i class=\"fa fa-pencil\"></i>  Can you find which is the more common Illumina sequencing error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-comment\"></i> The most common are errors to sequence repeated regions\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are using is \"almost\" raw data as it came from the Illumina sequencer. This data has been post-processed by the 1000GP consortium: for example, the adapters that the process of sequencing DNA via Illumina technology requires have been removed. This process is called **trimming**. We can still evaluate the quality of the assembly by checking different metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Sequence coverage\n",
    "\n",
    "We can use again `samtools` to calculate the **sequence coverage** (or sequencing depth). This metrics refers to the number of reads that include a specific nucleotide of a reference genome.\n",
    "\n",
    "The command is as follows: \n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">   \n",
    "    <code style=\"background-color:#222D32; color:#FFF\">samtools depth bamfile  |  awk '{sum+=$3} END { print \"Average = \",sum/NR}'\n",
    "</code>\n",
    "</div>\n",
    "\n",
    "`samtools depth` computes the depth at each position or region. The result is a file where the first column is the name of the chromosome, the second column is the base position and the third column is the depth of coverage for that base. The output is used as an input of the `awk`, that computes the average of the third column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Calculate the sequence coverage of your individual\n",
    "\n",
    "cd ..\n",
    "cd ..\n",
    "cd bams\n",
    "samtools depth HG03006.BEB.chr2:134800000-137500000.bam | awk '{sum+=$3} END { print \"Average = \",sum/NR}'\n",
    "\n",
    "# Average = 53.1694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 The `fastq` file format\n",
    "\n",
    "The **FASTQ format** is a text-based format for storing both a biological sequence (usually nucleotide sequence) and its corresponding quality scores. Both the sequence letter and quality score are each [encoded with a single ASCII character](https://drive5.com/usearch/manual/quality_score.html) for brevity. \n",
    "\n",
    "We can transform a BAM file to a `fastqc` file using `samtools bam2fq`:\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">samtools bam2fq bamfile > file.fastq</code>\n",
    "</div><br>\n",
    "\n",
    "This is the structure of a `fastq` file:\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/fastqc2019_10_27D19_41_46.png\" width=50%>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <i class=\"fa fa-cogs\"></i> Step 1: Create an `analysis` folder\n",
    "\n",
    "Create a folder named `analysis` inside your `ProjectP1` folder. Create the folder `qualityControl` inside the `analysis` folder. \n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/structure32019_10_27D19_47_19.png\" width=25%>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create the folders and navigate to qualityControl\n",
    "\n",
    "cd ..\n",
    "cd ..\n",
    "mkdir analysis\n",
    "cd analysis\n",
    "mkdir qualityControl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <i class=\"fa fa-cogs\"></i> Step 2: Run `samtools bam2fq` to transform the `bam` file to a `fastq` file\n",
    "\n",
    "Inside the `qualityControl` folder, run the command to transform the BAM file to a FASTQ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Run bam2fq\n",
    "\n",
    "samtools bam2fq ~/Escritorio/ProjectP1/data/bams/HG03006.BEB.chr2:134800000-137500000 > BEB.fastq\n",
    "\n",
    "# 600059 reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <i class=\"fa fa-cogs\"></i> Step 3: Run `fastqc` to analyze the `fastq` file\n",
    "\n",
    "[FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) is a very simple program that provides information about the sequence read quality.\n",
    "\n",
    "The basic command looks like:\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">fastqc -o resultsDirectory file.fastq</code>\n",
    "</div><br>\n",
    "\n",
    "It will generate a HTML report file in the directory specified in `resultsDirectory` (e.g.: create a folder named `fastqcResults` inside `qualityControl`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a folder\n",
    "\n",
    "# Run fastqc\n",
    "\n",
    "mkdir fastqcResults\n",
    "fastqc -o fastqcResults BEB.fastq\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <i class=\"fa fa-pencil\"></i>  Explore the HTML file with the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-comment\"></i> Results graphics show a negative quality per base. Reads quality is better than graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #86CBBB; 1px; height:3px \" ></div>\n",
    "\n",
    "# 7. Read mapping\n",
    "\n",
    "Typically, in this type of NGS analysis, a common step is to map the sequenced reads to a reference genome. However, this is not necessary since we already have aligned BAM files, which are precisely the files obtained after mapping reads against a reference genome. \n",
    "\n",
    "What we are going to do in this section is the mapping post-processing: cleaning the bam data and check the statistics.\n",
    "\n",
    "###  <i class=\"fa fa-cogs\"></i> Step 1: Create a `mapping` folder\n",
    "\n",
    "Create a folder named `mapping` inside your `analysis` folder.\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/structure42019_10_27D19_58_55.png\" width=30%>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create folders\n",
    "\n",
    "mkdir mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Mapping post-processing \n",
    "\n",
    "### 7.1.1 Fix mates and compress\n",
    "\n",
    "Because aligners can sometimes leave unusual flag information on the data, it is helpful to first clean up read pairing information and flags with `samtools`.\n",
    "\n",
    "Note, `samtools fixmate` expects name-sorted input files, which we can achieve first with `samtools sort -n`.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">samtools sort -n -O bam bamfile | samtools fixmate -m -O bam - fixmate.bam</code>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Fix mates and compress\n",
    "\n",
    "samtools sort -n -O bam ~/Escritorio/ProjectP1/data/bams/HG03006.BEB.chr2:134800000-137500000.bam | samtools fixmate -m -O bam - fixmate.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 7.1.2 Sorting\n",
    "\n",
    "We are going to use `samtools` again to sort the BAM file into coordinate order:\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">samtools sort -O bam -o sorted.bam fixmate.bam</code>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Fix mates and compress\n",
    "\n",
    "samtools sort -O bam -o sorted.bam fixmate.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 Remove duplicates\n",
    "\n",
    "In this step we remove duplicate reads. The main purpose of removing duplicates is to mitigate the effects of PCR amplification bias introduced during library construction. This step is not necessary because this NGS analysis was performed PCR-free.\n",
    "\n",
    "It should be noted that this step is not always recommended. It depends on the research question. In SNP calling it is a good idea to remove duplicates, as the statistics used in the tools that call SNPs sub-sequently expect this. However, for other research questions that use mapping, you might not want to remove duplicates, e.g. when performing a RNA-seq experiment, since you want to precisely quantify which genomic regions have more reads (i.e., are more expressed) than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Mapping statistics\n",
    "\n",
    "After the post processing, it's interesting to get some statistics. For that, we use again `samtools`. \n",
    "\n",
    "Let's get a mapping overview:\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">samtools flagstat sorted.bam</code>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Obtain flagstat statistics\n",
    "\n",
    "samtools flagstat sorted.bam\n",
    "\n",
    "608157 + 0 in total (QC-passed reads + QC-failed reads)\n",
    "8098 + 0 secondary\n",
    "0 + 0 supplementary\n",
    "0 + 0 duplicates\n",
    "601968 + 0 mapped (98.98% : N/A)\n",
    "593398 + 0 paired in sequencing\n",
    "296699 + 0 read1\n",
    "296699 + 0 read2\n",
    "580076 + 0 properly paired (97.75% : N/A)\n",
    "581020 + 0 with itself and mate mapped\n",
    "6189 + 0 singletons (1.04% : N/A)\n",
    "0 + 0 with mate mapped to a different chr\n",
    "0 + 0 with mate mapped to a different chr (mapQ>=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sorted BAM file we can get read depth for all positions of the reference genome, e.g. how many reads are overlapping each genomic position.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">samtools depth sorted.bam | gzip > sorted.depth.txt.gz</code>\n",
    "</div><br>\n",
    "\n",
    "<i class=\"fa fa-warning\"></i> Save this file as it will be used in  P2.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 7.3 Sub-selecting reads\n",
    "\n",
    "Finally, in this section, we want to sub-select reads based on the **quality of the mapping**. It seems a reasonable idea to only keep good mapping reads. As the SAM-format contains at column 5 the *MAPQ* value, which  stands for the \"MAPping Quality\" in Phred-scaled, this seems easily achieved. The formula to calculate the *MAPQ* value is:\n",
    "\n",
    "$MAPQ=−10*log_{10}(p)$\n",
    "\n",
    "where $p$ is the probability that the read is mapped wrongly. Typically a $p$ value of 0.01 is used. \n",
    "\n",
    "To filter by quality, the command is as follows:\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">samtools view -h -b -q MAPQVALUE sorted.bam > sorted.qMAPQVALUE.bam</code>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Filter by quality\n",
    "\n",
    "samtools view -h -b -q 20 sorted.bam > sorted.q20.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #86CBBB; 1px; height:3px \" ></div>\n",
    "\n",
    "# 8. Variant calling\n",
    "\n",
    "## 8.1 SAMtools mpileup\n",
    "\n",
    "The **variant calling** is the process of identifying differences (e.g., SNPs or indels) in a genomic sequence when compared against some reference sequence at a given position in an individual genome or transcriptome.\n",
    "\n",
    "To detect this variants, we are going to use `samtools mpileup`.\n",
    "\n",
    "###  <i class=\"fa fa-cogs\"></i> Step 1: Create a `variant` folder\n",
    "\n",
    "Create a folder named `variants` inside your `analysis` folder. \n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/structure52019_10_28D16_18_49.png\" width=25%>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create folder variants\n",
    " cd ..\n",
    " mkdir variants\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the sorted filtered BAM file that we produced in the mapping step before. We need to pass the \n",
    "following parameters to SAMtools `mpileup`:\n",
    "\n",
    "- `Q INT`: minimum base quality for a base to be considered (we normally use a minimum base quality of 20)\n",
    "- `q INT`: skip alignments with MAPQ smaller than INT (we normally use a minimum base quality of 20)\n",
    "- `u`: output uncompressed BAM\n",
    "- `g`: compute genotype likelihoods and output them in the binary call format (BCF)\n",
    "- `f FASTA`: the faidx-indexed reference file in the FASTA format\n",
    "\n",
    "The output of `mpileup` goes to `bcftools call` with the following parameters\n",
    "- `v`:  output variant sites only\n",
    "- `m`: alternative model for multiallelic and rare-variant calling\n",
    "- `O z`: output type: ‘z’ compressed VCF\n",
    "- `o`: name of the output file\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">samtools  mpileup -Q INT -q INT -u -g -f  reference.fasta sorted.qMAPQVALUE.bam | bcftools call -v -m -O z -o file.vcf.gz # VCF for one</code>\n",
    "</div><br>\n",
    "\n",
    "This will create a VCF file containing all the differences between an individial and a reference genome.\n",
    "\n",
    "<i class=\"fa fa-key\"></i> How can you create a file containing the differences of all the individuals of your metapopulation with respect a reference genome? Simply add the names of the BAM files of the other individuals next to the first BAM name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Call variants\n",
    "\n",
    "# pendiente\n",
    "\n",
    "samtools mpileup -Q 20 -q 20 -u -g -f ~/Escritorio/ProjectP1/data/assembly/human_g1k_v37.fasta ~/Escritorio/ProjectP1/analysis/mapping/sorted.q20.bam | bcftools call -v -m -O z -o VCF.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 8.1.1 Understanding the output files (VCF file)\n",
    "\n",
    "#### <i class=\"fa fa-search\"></i> Explore the VCF file you just created, using as a example the following commands:\n",
    "\n",
    "To see the first 10 lines, you can write:\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">zcat file.vcf.gz | head</code>\n",
    "</div><br>\n",
    "\n",
    "To look at the first four entries:\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">zcat file.vcf.gz | egrep -v '##' | head -4</code>\n",
    "</div><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Exploring the VCF file\n",
    " zcat VCF.vcf.gz | head\n",
    " zcat VCF.vcf.gz | egrep -v '##' | head -4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <i class=\"fa fa-pencil\"></i> Complete the following table with the columns that are contained in a VCF file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column | Description |\n",
    "|--------|-----------------|\n",
    "| CHROM | Chromosome name |\n",
    "| 2 | 134799928 |\n",
    "| 2 | 134800060 |\n",
    "| 2 | 134800786 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 VCF statistics \n",
    "\n",
    "Now that we understand a VCF file, we can use it to do some statistics and filter our variant calls. We can use the `bcftools stats` that needs the FASTA of the reference genome and the VCF file and will output a file containing the statistics.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">bcftools stats -F reference.fasta -s - file.vcf.gz > file.vcf.gz.stats</code>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Obtain stats\n",
    "\n",
    "bcftools stats -F ~/Escritorio/ProjectP1/data/assembly/human_g1k_v37.fasta -s - VCF.vcf.gz > VCF.vcf.gz.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i class=\"fa fa-search\"></i> Explore the stats file you just created, using the commands you know to explore a file (`cat`, `head`...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Exploration\n",
    "\n",
    "zcat VCF.vcf.gz.stats | head\n",
    "zcat VCF.vcf.gz.stats | egrep -v '##' | head -4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `plot-vcfstats` to create separated files ready-to-plot from the stats file that we will use in P2 to visualize. For that, create first a folder inside the `variants` folder called `plots`.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">plot-vcfstats -p plots file.vcf.gz.stats\n",
    "</code>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Exploration\n",
    "\n",
    "plot-vcfstats -p plots ~/Escritorio/ProjectP1/analysis/variants/VCF.vcf.gz.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-warning\"></i> Save these files as it will be used in  P2.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 Filter only biallelic SNPs\n",
    "\n",
    "After exploring the VCF file, you should have notice that there are different types of variants: SNPs, indels, etc. \n",
    "\n",
    "There is a specific command of `bcftools` that allows you to filter only biallelic SNPs:\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">bcftools view -m2 -M2 -v snps file.vcf.gz > fileBiallelic.vcf\n",
    "</code>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Biallelics \n",
    "\n",
    "bcftools view -m2 -M2 -v snps ~/Escritorio/ProjectP1/analysis/variants/VCF.vcf.gz > Biallelic.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i class=\"fa fa-pencil\"></i> How many SNPs have each individual that you have analyzed? Do you observe differences when comparing individuals of different geographic origin? Compare your results with the rest of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-comment\"></i> \n",
    "\n",
    "The Bengali population has 3131 SNPs, it is a much higher amount than other populations in the region.\n",
    "\n",
    "This can be explained by the partial isolation of individuals from other regions, decreasing their allelic diversity.\n",
    "\n",
    "In the case of the other regions, we see that Africa has many more SNPs, and it is expected since it is the area where Homo sapiens emerged and there is enormous diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Variant analysis\n",
    "\n",
    "### 8.3.1 SNPs in common\n",
    "\n",
    "One interesting thing is to find out how many SNPs are in common between the individuals. For that we can use specific `bash` commands :\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">grep -v \"#\" 4_samples.flt_snps.SAM.vcf | wc -l\n",
    "</code>\n",
    "</div><br>\n",
    "\n",
    "To find the SNPs in common between the individuals, you can simply use the `wc -l` command to count how many rows the vcf file has after cleaning the header (lines that start with a `#` symbol). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# SNPs in common\n",
    "\n",
    "grep -v \"#\" 4_samples.flt_snps.SAM.vcf | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2 Fixed and heterozygous SNPs\n",
    "\n",
    "The `GT` column of the VCF file indicates the status of the two alleles carried by the sample. It can be\n",
    "encoded by a 0 for the reference allele and 1 for the alternative allele. If the genotype is 0/0, means that the sample is homozygous for the reference genotype. If its 0/1, means that the sample is heterozygous and 1/1 means that the sample is homozygous for the alternative genotype. ./. means that the sample misses genotype.\n",
    "\n",
    "To analyse the number of fixed and heterozygous SNPs in your sample, you can use gain the `grep` command to find how many SNPs have the 0/0 status, or 0/1 status, or 1/1 status. For example, the following command will give you the total number of heterozygous SNPs in the individual 1.\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">grep \"0/1\" snps_sample1.txt | wc -l\n",
    "</code>\n",
    "</div><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Grep heterozygous SNPs\n",
    "\n",
    "grep \"0/1\" Biallelic.vcf | wc -l\n",
    "\n",
    "\n",
    "# Grep fixed SNPs\n",
    "\n",
    "grep \"0/0\" Biallelic.vcf | wc -l\n",
    "\n",
    "grep \"1/1\" Biallelic.vcf | wc -l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #86CBBB; 1px; height:3px \" ></div>\n",
    "\n",
    "# 9. Diversity metrics\n",
    "\n",
    "`vcftools` software has some useful options that allows you to calculate some metrics in sliding windows of the genome. \n",
    "\n",
    "\n",
    "###  <i class=\"fa fa-cogs\"></i> Step 1: Create a folder in your working directory\n",
    "\n",
    "Create a folder named `diversity` inside your `analysis` folder. \n",
    "\n",
    "<center>\n",
    "    <img src=\"https://bioinformatica.uab.cat/base/documents/sgbcursos/documents/structure62019_10_29D10_2_25.png\" width=30%>\n",
    "</center>\n",
    "\n",
    "\n",
    "One of the most common diversity metrics that we can estimate when using population genomic data is the nucleotide diversity using the $\\pi$ metric. The nucleotide diversity is used to measure the degree of polymorphism within a population.\n",
    "\n",
    "To use it, you simply pass the vcf file and the size of the window you want to estimate the metric.\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">vcftools --gzvcf file.vcf.gz --window-pi windowsize\n",
    "</code>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Get nucleotide diversity\n",
    "\n",
    "vcftools --gzvcf ~/Escritorio/ProjectP1/analysis/variants/VCF.vcf.gz --window-pi windowsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting statistic is the SNP density metric, that calculates the number and density of SNPs in windows of size defined by this option.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color:#222D32; color:#FFF\">\n",
    "    <code style=\"background-color:#222D32; color:#FFF\">vcftools --gzvcf file.vcf.gz  --SNPdensity windowsize\n",
    "</code>\n",
    "    \n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Get SNP density\n",
    "\n",
    "vcftools --gzvcf ~/Escritorio/ProjectP1/analysis/variants/VCF.vcf.gz  --SNPdensity windowsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <i class=\"fa fa-warning\"></i> Save the previous results in two files to visualize in P2.\n",
    "\n",
    "#### <i class=\"fa fa-pencil\"></i> Compare these two metrics in different populations. What differences do you observe? Which populations have more nucleotide diversity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-comment\"></i> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #86CBBB; 1px; height:3px \" ></div>\n",
    "\n",
    "# 10. Discovering the effect of variants "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SNP annotation** is the process of predicting the effect or functional consequence of individual SNPs using annotation tools. One of the most used annotating tools is the Ensembl Variant Effect Predictor ([VEP](https://www.ensembl.org/info/docs/tools/vep/index.html)), which can be used as a [web service](https://www.ensembl.org/Tools/VEP) or through the [command line](https://anaconda.org/bioconda/ensembl-vep). \n",
    "\n",
    "###  <i class=\"fa fa-cogs\"></i> Use VEP to investigate the effect of your variants, trying to find how many missense and synonymous SNPs you have in your sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-comment\"></i> Through VEP we see that 41% of the variants are \"missense_variant\" and 14% are \"synonymous_variant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <i class=\"fa fa-warning\"></i> Save the VEP annotation file to visualize in P2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
